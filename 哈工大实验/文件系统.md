# 文件系统

> 从一个磁盘到文件再到文件系统的漫长抽象

用户对操作系统的使用是以文件为基础的，我们编辑的文档，执行的命令，使用的外部设备在操作系统哪里都是文件。虽然是文件系统，**但归根结底是对磁盘的驱动**。具体来说，在磁盘启动过程中发现直接使用磁盘很繁琐，因此引入了五层抽象机制：（1）从扇区到磁盘块的抽象，（2）从单个磁盘块到多进程的磁盘请求队列，（3）从磁盘请求到高速缓存，（4）从盘块集合到文件的抽象，（5）从多个文件到构建文件系统

## 磁盘工作的基本原理

包含两条主线：（1）从CPU开始，当用户想要使用磁盘时，由CPU发送命令给磁盘设备，最终通过"out ax,端口号"指令告诉磁盘具体的动作细节。（2）从磁盘开始，即磁盘在工作完成后用磁盘中断告诉CPU，CPU在中断处理中完成后续细节，如将磁盘读入的内容复制到用户态内存buf中。

### 磁盘工作的过程

磁盘是由多个圆形盘形成的盘面组，每个盘面上又有多个同心圆环，每个同心圆环被称为一个磁道，多个磁道的同一磁道合在一起形成一个圆柱面，简称柱面。每个磁道再被分割为多个扇区，扇区是磁盘读写的基本单位。由于有多个盘面，所以在每个盘面上都有一个读写磁头，进行磁盘读写时，只有一个磁头是上电的，会读写上电磁头对应的哪个磁道上的那个扇区。

![屏幕截图 2022-07-17 152336](E:\操作系统（哈工大实验，笔记）\imags\屏幕截图 2022-07-17 152336.png)

磁盘读写的过程是：

- 磁头移动，找到要读的那个柱面，由于多个磁头是绑在一起移动的，所以每个磁头下面的磁道在各自的盘面中具有相同的位置，所有磁头下面的磁道从上到下组合在一起就形成了一个”柱面“。
- 从柱面中选择要具体读写哪个磁道，实际上就是选择哪个磁头上电。
- 旋转磁盘将对应磁道中要读写的那个扇区转到磁头的下方。
- 开始读写，将扇区中的内容读到内存缓冲区中，或者是将内存缓冲区中的内容写出到该扇区。

### 使用磁盘的直观方法

一个很直观的想法是：让CPU给磁盘控制器发出读写命令，具体就是告诉磁盘控制器读写哪个柱面C，哪个磁头H，哪个扇区S以及要读写的内存缓冲区的位置和读写长度。当然需要去查硬件手册，找到这些信息对应的端口地址，一旦找到以后，CPU用out指令将这些信息写出去即可，磁盘控制器一旦看到了这些信息就会执行磁头滑动，磁盘旋转以及读写扇区等动作了。

```c
void do_hd_request(void) {
    hd_out(dev,nsect,sec,head,cyl,WRITE,);
    port_write(HD_DATA,CURRENT->buffer,256);
}

void hd_out(drive,nsect,sec,head,cyl,cmd) {
    port = HD_DATA;// 数据寄存器端口(0x1f0)
    outb_p(nsect,++port);
    outb_p(sect,++port);
    outb_p(cyl,++port);
    outb_port(cyl>>8,++port);
    outb_p(0xA0|drive<<4)|head,++port);
    outb_p(cmd,++port);
}
```

在这段磁盘直接读写代码中，hd_out用来将驱动器信息drive，读写长度信息nsect，读写扇区号sect，读写磁头号head，读写柱面号cyl以及读或写的命令cmd等信息用outb_p(......++port)语句写到端口port上。在CPU将这些命令发出到磁盘控制器以后，用port_write或port_read实现内存缓冲区CURRENT->buffer和磁盘控制器的数据寄存器端口HD_DATA之间的数据交换，这个交换的核心还是out指令和in指令。

```c
#define port_write(port,buf,nr) __asm__("cld;rep;outsw"::
"d"(port),"S"(buf),"c"(nr))
#define port_read(port,buf,nr) __asm__("cld;rep;insw"::
"d"(port),"S"(buf),"c"(nr))
```

## 生磁盘的使用

### 第一层抽象：从扇区到磁盘块请求

对于上层用户（程序员）来说，通过直接操作柱面C，磁头H，扇区S来读写磁盘扇区显然太繁琐，我们期望一种更符合人们习惯的磁盘读写。抹去C,H,S等具体细节，让用户感受就是访问一大堆扇区排成一排等待用户使用，让用户访问第0，1，....10000......个扇区，这样的访问请求显然要方便得多。实现这种访问的核心是**建立从C,H,S扇区地址到扇区号的一个映射**。

显然，0号扇区可以规定在0柱面（可以规定为最外面那个柱面），0磁头（可以规定为最上面的那个磁头），0扇区（可以规定为磁盘旋转整圈以后的那个扇区）位置上。对后续扇区号的编址，我们的希望可以提高磁盘读写速度，也即相邻扇区号之间的扇区在磁盘上的位置使得从上一个扇区号到下一个扇区号花的时间最少。

分析前面的磁盘读写过程，磁盘读写主要分为三步：移动磁臂（也成为寻道），旋转磁盘，数据传输。移动磁道通常需要花费10ms左右，旋转时间为4ms，传输时间为0.04s。

![屏幕截图 2022-07-17 163400](E:\操作系统（哈工大实验，笔记）\imags\屏幕截图 2022-07-17 163400.png)

将上述公式化简得到：`sector = (C x Heads + H) x Sectors + S`，基于此公式我们就可以通过扇区号得到C,H,S

```c
S = sectors%Sectors;
H = sector/Sectors%Heads;
C = sector/Sectors/Heads; 
```

**接下来要引入磁盘块的概念**：

我们希望每次读写多个连续扇区而不是一个扇区，因为数据传输和寻道/旋转的时间相比要小得多，所以寻道/旋转依次读写k个扇区相比于只读一个扇区来说器磁盘读写速度提高接近于k倍。但是带来的缺点是会造成磁盘空间的浪费。有了磁盘块之后，用户发出的磁盘请求就是盘块号blocknr，由于磁盘块是连续的多个扇区，可以很容易算出扇区号。

```c
sector = blocknr X blocksize
```

下面给出了这一层抽象的具体实现，根据上层用户发出的磁盘请求可以构造数据结构request。

```c
static void make_request() {
    struct request *req;
    req = request + NR_REQUEST;
    req->sector = bh->b_blocknr<<1;
    add_request(major+blk_dev,req);
}
```

### 第二层抽象：多个进程产生的磁盘请求队列

因为操作系统中有多个进程，每个进程都会提出磁盘块访问请求，所以在实际操作系统中是多个进程产生多个磁盘块读写请求的情形。多个磁盘读写请求，需要用队列来组织这些请求，这就是操作系统对磁盘管理的第二层抽象。

经过第一层抽象以后，我们只要告诉操作系统要读写的盘块号就可以完成磁盘读写。而经过第二层抽象以后，想进行磁盘读写的进程首先建立一个磁盘读写请求数据结构，并在这个数据结构中填上要读写的盘块号，然后将这个数据结构放入磁盘请求队列。如何在多个请求中选择一个合适的请求来分配资源。

#### FCFS

对于磁盘请求队列，我们直接在代码层面设计为一个队列，先来的请求先进行处理。这样肯定是不行的。

![屏幕截图 2022-07-17 172224](E:\操作系统（哈工大实验，笔记）\imags\屏幕截图 2022-07-17 172224.png)

#### SSTF(最短寻道时间优先)

每次都选择离当前磁头最近的柱面请求进行处理。我所考虑的问题是，你每次都需要将所有请求都扫描一遍找到一个离当前磁头最近的，当然你也可以每次请求进来的时候都进行插入排序，然后按着排序之后的请求进行处理。不管怎么样你都需要对这些请求进行比对，这是需要耗费时间的。另外我们当前处理磁盘请求仍然处于操作系统内核态，磁盘请求队列肯定放在内核内存中。

![屏幕截图 2022-07-17 172932](E:\操作系统（哈工大实验，笔记）\imags\屏幕截图 2022-07-17 172932.png)

SSTF存在的问题是它是一个贪心算法，它仅仅考虑当前最优，不考虑对未来产生的影响。另外SSTF还会导致对用户磁盘请求的服务机会不均等，当磁盘读写请求很多时，处于两端柱面的磁盘请求可能会被无限期延迟。（你不停的进来中间柱面的请求）

#### SCAN

首先朝一个方向（比如说小于当前盘块号的请求），处理经过的所有请求，直到这个方向不再有磁盘请求时，磁头开始向另一个方向扫描，并处理经过的所有请求。

缺点是中间的柱面请求还是占了便宜，要比两端的柱面请求得到更快的处理。

![屏幕截图 2022-07-17 173534](E:\操作系统（哈工大实验，笔记）\imags\屏幕截图 2022-07-17 173534.png)

#### CSCAN

不进行摆动扫描，采用复位扫描。

![屏幕截图 2022-07-17 173544](E:\操作系统（哈工大实验，笔记）\imags\屏幕截图 2022-07-17 173544.png)

**现在我们可以开始具体实现多进程对磁盘的访问了：**

- 进程提出磁盘读写请求就是新建一个磁盘请求数据结构req，可以用函数make_request()来产生req，并在req中填入盘块号等信息。
- 将请求req加入到操作系统中的磁盘请求电梯队列中，在添加时就要保证磁盘请求队列具有电梯队列的形状。并且需要进行临界区的保护
- 1磁盘从角度考虑（这是另一条线，产生请求与处理请求之间没有必然关系，用户不断的在产生请求，而磁盘在不断的处理请求），在磁盘中断处理时，也就是上一个磁盘请求处理完之后发出的中断。从电梯队列中取出一个请求进行处理。由于添加时就要保证磁盘请求队列具有电梯队列的形状，所以只需要取出位于队列首部的请求即可。
- 取出磁盘读写请求之后要做的就是取出请求数据结构中的盘块号，算出C,H,S信息，用out指令发出去。

```c
static void make_request() {
    req->sector = bh->b_blocknr<<1;
    add_request(major+blk_dev,req);
}

static add_request(struct blk_dev_struct *dev,struct request *req) {
    struct request *tmp = dev->current_request;
    req->next = NULL;
    cli();// 关中断（进入临界区）
    for(;tmp->next;tmp = tmp->next){
        if ((IN_ORDER(tmp,req) || !IN_ORDERED(tmp,tmp->next)) && IN_ORDERED(req,tmp->next)) {
            break;
        }
        req->next = tmp->next;
        tmp->next = req;
    }
}
```

add_request在电梯队列中插入磁盘请求req，保证插入请求之后的队列仍然保持电梯队列形状。使用` if ((IN_ORDER(tmp,req) || !IN_ORDERED(tmp,tmp->next)) && IN_ORDERED(req,tmp->next))`来寻找req在电梯队列中的插入位置。我们假设我们的电梯队列的扫描方向是从小到大。因为我们采取的复位扫描，所以整个请求排成的队列可能是有两条。我们仅仅考虑当前状态下的电梯队列，不存在进入请求的情况，那就是从当前请求开始到最大盘块号请求为一个队列，倘若存在比当前请求的盘块号还小的请求，那就复位再从小到大扫描一次。考虑进入一个请求，可能存在两种情况。第一种情况是`(IN_ORDER(tmp,req)&& IN_ORDERED(req,tmp->next)`，这是指req在tmp和tmp->next的中间，这可能在第一个队列上，也可能在第二个队列上，如下图所示：

![cscan](E:\操作系统（哈工大实验，笔记）\imags\cscan.png)

第二中情况是`!IN_ORDERED(tmp,tmp->next)&& IN_ORDERED(req,tmp->next)`，这种情况代表着新来的请求req位于第二个队列的首位，那自然比tmp小，也比tmp->next也小。

每次磁盘控制器处理完一个磁盘请求之后，会产生磁盘中断。磁盘中断处理函数read(write)_intr代码如下：

```c
// 磁盘中断处理代码
static void read(write)_intr(void){
    end_request(1);
    do_hd_request();
}

do_hed_request(){
    扇区号 = CURRENT->sector;
    根据扇区号算出C,H,S;
    hd_out(C,H,S,...);
}
```

首先执行end_request，在其中唤醒一个进程，也就是正在等待那个磁盘请求的进程。do_hd_request处理下一个磁盘请求，即电梯队列中位于队首的那个请求，实现代码为block = CURRENT->sector，这里的CURRENT是一个全局指针，用来指向电梯队列的队首元素。

### 第三层抽象：从磁盘请求到高速缓存

整理一下到目前位置的磁盘处理过程：操作系统处理各个进程提出的磁盘请求，根据请求中的磁盘块号在磁盘上找到相应的扇区位置，将这些扇区读入到内核态内存中，然后再由系统调用（如sys_read）将放于内核态中的磁盘数据复制到用户态内存中，用户态程序操作用户态内存中的数据。

根据上述过程，磁盘读写时的数据要经过用户态内存，内核态内存以及磁盘扇区三个地方。根据这一磁盘访问结构，很可能出现这样的情况：用户要从磁盘上读100B的内容，由于磁盘的读写单位是磁盘块，所以虽然用户要读100B，但真正读入的数据内容很可能要大于100B，以linux0.11为例，一个磁盘块的大小是两个扇区也就是1024B，那么**根据程序的局部性**，很可能会处理下一个100B，这时就没必要再去读磁盘了，因为刚才读入的1024B仍然保留再内核态内存中。

磁盘高速缓存是磁盘的又一层抽象，从用户角度出发，磁盘读写变成了高速缓存读写，用户向高速缓存发出读写请求，如果用户i请求的数据在高速缓存中，操作系统会直接将信息返回；如果不在才发出磁盘请求区读写磁盘。可以理解到的是高速缓存其实就是内存的一块空间用来存储最近在磁盘中访问的数据，那么如何设计和实现磁盘高速缓存机制就很显然了。首先，我们用什么数据结构去组织这个高速缓存，使得能够快速查找一个磁盘块数据是否在高速缓存中。另外，如果发现高速缓存中没有用户请求的磁盘块，此时应该去读取磁盘，这就要求提供空闲缓冲区，取出以一个空闲缓冲块，用来缓冲从物理磁盘中读出的数据。也就是说设计磁盘高速缓存的核心就是建立两个数据结构，用一个散列表组织有内容的缓存块，再用一个空闲链表组织那些空闲的缓存块。

当用户发起磁盘请求的时候，操作系统内核直接转向对高速缓存的请求

```c
struct buffer_head * bread(int dev, int block) {
    struct buffer_head *bh;
    bh = getblk(dev,block);
    if (bh->b_uptodate) {
        return bh;
    }
    make_request(READ,bh);
    wait_on_buffer(bh);
    return bh;
}
```

getblk函数查找高速缓存散列表，看其中是否已经存有块号为block的磁盘块数据，如果找到了，那么`if (bh->b_uptodate)`的判断条件就为真，此时直接返回，如果没有找到，此时getblk会从空闲链表中分配一个空闲缓存块bh，交由后续函数处理。接下来就是真正读写磁盘，也就是建立请求req，放入电梯队列...

对于上层应用来说，磁盘请求放入电梯队列以后磁盘读写工作就完成了，真正什么时候开始磁盘读写，是交由磁盘中断处理程序去调度的。所以用户进程在将磁盘读写请求放入电梯队列以后就可以睡眠等待了，函数wait_on_buffer()用来将发出磁盘请求的当前进程等待在缓存块bh上。将来磁盘中断处理时会执行end_request，那时候就会唤醒等待在bh上的进程。

## 基于文件的磁盘使用

### 第四层抽象：引出文件

为了让磁盘上的数据访问更符合人们的习惯，操作系统引出了磁盘使用的第四层抽象——文件。文件是一个字符流，建立了字符流到盘块号的映射。比如test.c文件中的第200个字节对应在哪个磁盘块上，我们通过映射表来记录这种映射关系。（当然我们不仅需要找到在哪个磁盘块上，也得知道在该磁盘块上的第几个字节，这个是很容易算出的）

#### 顺序存储

对于一个给定文件，将其字符流连续存放在磁盘块上。创建文件时，操作系统会将文件对应的字符流存放在盘块号连续的多个磁盘块上，然后将存放字符流的第一个盘块号填写在该文件的FCB上。在用户要访问字符流位置pos时，操作系统会从该文件的FCB上取出起始块号start_blocknr，然后通过公式

```c
blocknr = start_blocknr + pos / BLOCK_SIZE
```

计算出该字符流位置所在的磁盘块号，剩下的工作就是用盘块号来读写磁盘了。

这种方案在访问任何一个字符流位置都能根据上面的公式快速计算处对应的磁盘块号。但是如果需要对文件进行改写，比如要在文件的某个位置添加一些字符。为了保证添加以后的字符流在磁盘上仍连续存放，需要将这个中间位置以后的磁盘块内容全部往后挪动。

#### 链式存储结构

![屏幕截图 2022-07-19 164952](E:\操作系统（哈工大实验，笔记）\imags\屏幕截图 2022-07-19 164952.png)

#### 索引结构

文件字符流被分割成多个逻辑块，在物理磁盘上寻找一些空闲物理块（无须连续），将这些逻辑块的内容存放进去，再找一个逻辑块作为索引块，其中按序存放各个逻辑块对应的物理磁盘块号。

![屏幕截图 2022-07-19 165118](E:\操作系统（哈工大实验，笔记）\imags\屏幕截图 2022-07-19 165118.png)

引出一些细节问题：一个很小的文件，假设只有一个磁盘块大小的文件，还需要引入索引块吗？当一个文件很大时，存放字符流的磁盘块号数量太多，多到一个索引块容纳不下时该怎么办。？操作系统采用索引存储结构来解决上述问题，索引节点（也就是文件的FCB，因为是索引结构，所以通常被称作索引节点，index node，简称inode）中存放了直接数据块号，索引块号以及间接索引块号三个部分。直接数据块直接指向文件内容，字符流中的前六个逻辑块对应的磁盘块号可以用inode中的直接块信息直接获得。

#### 文件的实现

用户访问一个文件，我们基于文件句柄找到了这个文件，基于文件的inode中的索引信息以及字符流读写位置，我们就能找到文件读写位置所在的物理盘块号，然后利用这个盘块号去调用bread。

```c
// sys_write()函数的部分代码（普通文件分支）
int sys_write(int fd, const char *buf, int count){
    struct file *file = current->filp[fd];
    struct m_inode *inode = file->inode;
    if (S_ISREG(inode->i_mnode)){
        return file_write(inode,file,buf,count);
    }
}
```

根据inode->i_mode进行分支判断，此时inode对应的不是字符设备，而是常规文件，会跳到file_write(inode,file,buf,count)去执行。

```c
// file_write() 函数的代码实现
int file_write(struct m_inode *inode,struct file *filp,char *buf,int count) {
    off_t ops;
    if (filp->f_flags & O_APPEND){
        pos = inode->i_size;
    }
    else {
        pos = filp->f_pos;
    }
    while (i < count) {
        block = create_lock(inode,pos/BLOCK_SIZE);
        bh = bread(inode->i_dev,block);
        int c = pos%BLOCK_SIZE;
        char *p = c + bh->b_data;
        bh->b_dirt = 1;
        c = BLOCK_SIZE - c;
        pos += c;
        while(c->0) {
            *(p++) = get_fs_byte(buf++);
        }
        brelse(bh);
    }
    filp->f_pos = pos;
}
```

file_write首先应该找到文件读写对应的字符流位置，而这个位置是通过文件读写指针隐式的告诉file_write。文件读写指针是文件的当前读写位置，更确切地说，是文件最近一次读写结束时停留地读写位置。也就是我们的pos变量，有了字符流上的读写位置pos，接下来需要根据pos和索引节点中的索引信息来计算物理盘块号。在函数create_block(inode,pos/BLOCK_SIZE)中会调用bmap来完成这项工作，其中pos/BLOCK_SIZE算出来的就是逻辑块号，用这个数值去查找inode中的直接数据块，一阶索引抑或是二阶索引就是这项工作的核心内容。

一旦找到物理盘块号，就可以利用物理盘块号去真正读写磁盘了。写磁盘其实就是写高速缓存。bh=bread(inode->i_dev,block)用来获得一个缓存块。接下来就是实现用户缓存buf（即用户态一段数据）和内核磁盘高速缓存bh->b_data之间的数据交换，将用户缓存中的字符逐个写到磁盘高速缓存中。在适当的时候，操作系统会将磁盘高速缓存中的这个磁盘读写请求放到电梯队列中，等磁盘中断的时候才真正写磁盘，这就是著名的磁盘延迟写。

此次文件读写完成以后需要修改f_pos，因为读写指针已经移动了，下一次文件访问时应该从新的字符流位置开始。

### 第五层抽象：将整个磁盘抽象成一个文件系统

在这一层抽象中主要考虑的问题是如何组织和管理一堆文件。最容易想到的组织方式是将很多个文件并列在一起，但这样很明显是不行的，面对多个文件，对于用户来说最重要的就是文件检索操作。我们应该对文件进行分类组织。

![屏幕截图 2022-07-20 154732](E:\操作系统（哈工大实验，笔记）\imags\屏幕截图 2022-07-20 154732.png)

在用户眼里，操作系统磁盘就是操作一颗目录树。用户可以访问这颗目录树，也可以修改这颗目录树，可以在目录树上添加新的目录和文件，也可以删除已有的目录和文件。实现磁盘的抽象就是实现目录树，目录树就是由文件和目录两部分组成，文件我们已经进行了详细论述，所以实现目录树的关键就是实现目录。

我们以`/my/data/a`文件路径为例，我们希望通过这个路径能够访问到a文件，能操作到a文件，而从操作系统层面来看，它需要知道a文件的FCB才能对其进行操作，也就是说我们需要找到a文件的FCB。那么如何找到a文件的FCB呢，一个很直观的想法是：在每个目录下都存放当前目录所有文件的FCB。那对应这个文件路径，我们所作的就是，首先用"my"在根目录下进行比对，找到了my的FCB，找到了my的FCB也就读入了my目录的内容，然后用"data"在my目录下进行比对，找到了data的FCB，依次类推最后也就找到了a文件的FCB。不难看出，目录解析由两项基本工作：

- 用"my"去目录内容中做比对
- 读入"my"的FCB后继续沿着目录树进行目录解析。

在目录下存入当前目录所有文件的FCB会造成磁盘空间代价，能否进行解决呢？我们可以存放一个FCB地址，一种常见的处理方法是将磁盘上所有文件的FCB数据结构组织成一个数组连续地存放在一个磁盘块序列上，此时一个文件的FCB地址就是这个文件的FCB数据结构在这个FCB数组里的索引。

这样设计之后，根目录的内容就是`[var 13] [my,82]`。首先读入根目录的内容，其中存放的是`[var 13] [my,82]`，根据路径名匹配字符串"my"，字符串匹配之后发现my目录文件的FCB编号为82，启动磁盘读在FCB数组中读出my的FCB，**然后根据my的FCB的信息找到存放my目录内容的磁盘块**，启动磁盘读将my目录的内容读出来。是`[data ,103] [cont, 225] [mail ,77]`。

需要交代的一点是：根目录中的内容如何获得，我们约定根目录的FCB一定放在FCB数组中的第一项，根据FCB中的信息从磁盘中读入根目录的内容。

另外，由于需要对目录树进行动态修改，所以必然涉及磁盘空闲数据块以及磁盘空闲FCB的管理。通常使用位图来描述磁盘上的物理盘块和FCB数据的使用情况。

![屏幕截图 2022-07-20 163539](E:\操作系统（哈工大实验，笔记）\imags\屏幕截图 2022-07-20 163539.png)

#### 目录解析的代码实现

open系统调用会触发目录解析，我们对目录解析代码实现的讨论从sys_open开始。

```c
// 在linux/fs/open.c中
int sys_open(const char* filename, int flag)
{ 
    i=open_namei(filename,flag,&inode);
	...
}

int open_namei(...)
{ 
    dir=dir_namei(pathname,&namelen,&basename);
   	...
}
 
static struct m_inode *dir_namei()
{ dir=get_dir(pathname); }
```

```c
// get_dir完成真正的目录解析
static struct m_inode *get_dir(const char *pathname)
{ 
    if((c=get_fs_byte(pathname))==‘/’) {
    	inode=current->root; pathname++;
	} 
	else if(c) inode=current->pwd;
	while(1) {
        if(!c) return inode; //函数的正确出口
		bh=find_entry(&inode,thisname,namelen,&de);
		int inr=de->inode; 
        int idev=inode->i_dev;
		inode=iget(idev,inr); //根据目录项读取下一层inode
    }
}
```

重点：

(1)root：找到根目录；

(2)find_entry：从目录中读取目录项；

(3)inr：是目录项中的索引节点号；

(4)iget：再读下一层目录

对于`current->root`如何理解，就是代表根目录，而根目录不是当前进程打开的，那一定是init进程打开的。

```c
void init(void)
{ 
    setup((void *) &drive_info);
    ... 
}

// 在kernel/hd.c中
sys_setup(void * BIOS)
{ 
    hd_info[drive].head = *(2+BIOS);
	hd_info[drive].sect = *(14+BIOS);
	mount_root(); 
    ...
}

// 在fs/super.c中
void mount_root(void) {
	mi=iget(ROOT_DEV,ROOT_INO));
	current->root = mi; 
}
```

`iget`函数第一个参数是设备号，第二个参数是对应目录在FCB数组中的索引。

```c
struct m_inode * iget(int dev, int nr)
{ 
    struct m_inode * inode = get_empty_inode();
	inode->i_dev=dev; inode->i_num=nr;
	read_inode(inode); return inode;
} 


static void read_inode(struct m_inode *inode)
{ 
    struct super_block *sb=get_super(inode->i_dev);; 
	lock_inode(inode); 
	block=2+sb->s_imap_blocks+sb->s_zmap_blocks+(inode->i_num-1)/INODES_PER_BLOCK;
	bh=bread(inode->i_dev,block);
	inode=bh->data[(inode->i_num-1)%INODES_PER_BLOCK];
	unlock_inode(inode); 
}
```

在read_inode中所做的就是先根据当前目录在FCB数组中的索引找到其在物理磁盘上的位置，也就是磁盘块号。

`block=2+sb->s_imap_blocks+sb->s_zmap_blocks+(inode->i_num-1)/INODES_PER_BLOCK;`前面两个代表引导块和超级块，后面两项分别是inode位图和数据盘块位图。`INODES_PER_BLOCK`代表每个磁盘块上有多少项FCB。基于此就能找到对应的磁盘块号，然后向高速缓存发出磁盘请求，真正的拿到我们的FCB（inode），并返回出去。